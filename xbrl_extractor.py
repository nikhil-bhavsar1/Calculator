# -*- coding: utf-8 -*-
"""xbrl_extractor.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HKdGiyG0ZCXs3BySF_5DKWz2dOaBw0mx
"""

import sys
import subprocess
import importlib
import xml.etree.ElementTree as ET
import os
import re # Import regular expression module
# Note: pandas and openpyxl are imported AFTER the check
from collections import defaultdict

def check_and_install_dependencies():
    """
    Checks for required dependencies and installs them if they are missing.
    """
    print("--- Checking required dependencies ---")

    # (import_name, install_name)
    required_packages = [
        ("pandas", "pandas"),
        ("openpyxl", "openpyxl")
    ]

    all_installed = True

    for import_name, install_name in required_packages:
        try:
            # Try to import the package
            importlib.import_module(import_name)
            print(f"[âœ“] {install_name} is already installed.")
        except ImportError:
            print(f"[!] {install_name} not found. Installing...")
            all_installed = False
            try:
                # Install the package using pip
                subprocess.check_call([sys.executable, "-m", "pip", "install", install_name])
                print(f"[âœ“] Successfully installed {install_name}.")
                # Verify installation by importing again
                importlib.import_module(import_name)
            except Exception as e:
                print(f"[X] ERROR: Failed to install {install_name}.")
                print(f"    Please install it manually using: pip install {install_name}")
                print(f"    Error details: {e}")
                sys.exit(1)

    if all_installed:
        print("--- All dependencies are satisfied. ---")
    else:
        print("--- All required dependencies are now installed. ---")
    print("\n")

# Run the dependency check *before* importing the packages
check_and_install_dependencies()

# --- Now we can safely import the packages ---
try:
    import pandas as pd
    import openpyxl # Used by pandas for Excel
except ImportError:
    print("\n[X] CRITICAL ERROR: Failed to import dependencies even after install attempt.")
    print("    Please close this and manually run:")
    print("    pip install pandas openpyxl")
    sys.exit(1)


def parse_xbrl_xml(xml_file):
    """
    Parses an XBRL XML file and extracts financial data.

    Args:
        xml_file (str): The path to the XML file.

    Returns:
        tuple: (header_data, financial_dataframe)
    """
    print(f"Parsing '{xml_file}'...")

    try:
        # Register namespaces to make searching easier
        # These are found at the top of the XML file
        namespaces = {
            'xbrli': 'http://www.xbrl.org/2003/instance',
            'in-capmkt': 'http://www.sebi.gov.in/xbrl/2025-01-31/in-capmkt',
            'iso4217': 'http://www.xbrl.org/2003/iso4217'
        }

        tree = ET.parse(xml_file)
        root = tree.getroot()

        # --- 1. Map Contexts (Periods) ---
        # Find all context tags and map their ID to a human-readable period
        contexts = {}
        for context in root.findall('xbrli:context', namespaces):
            context_id = context.get('id')
            period = context.find('xbrli:period', namespaces)
            if period is not None:
                instant = period.find('xbrli:instant', namespaces)
                if instant is not None:
                    contexts[context_id] = f"As of {instant.text}"
                else:
                    start_date = period.find('xbrli:startDate', namespaces)
                    end_date = period.find('xbrli:endDate', namespaces)
                    if start_date is not None and end_date is not None:
                        contexts[context_id] = f"{start_date.text} to {end_date.text}"
            else:
                contexts[context_id] = "N/A"

        # --- 2. Map Units ---
        units = {}
        for unit in root.findall('xbrli:unit', namespaces):
            unit_id = unit.get('id')
            measure = unit.find('xbrli:measure', namespaces)
            if measure is not None:
                units[unit_id] = measure.text.split(':')[-1] # e.g., 'iso4217:INR' -> 'INR'
            else:
                # Handle complex units like 'INRPerShare'
                divide = unit.find('xbrli:divide', namespaces)
                if divide is not None:
                    num = divide.find('xbrli:unitNumerator/xbrli:measure', namespaces).text.split(':')[-1]
                    den = divide.find('xbrli:unitDenominator/xbrli:measure', namespaces).text.split(':')[-1]
                    units[unit_id] = f"{num} per {den}"

        # --- 3. Extract Header Data (non-financial) ---
        # These are facts that don't have a unit (unitRef=None)
        header_data = {}
        for elem in root.findall('in-capmkt:*', namespaces):
            if elem.get('contextRef') and elem.get('unitRef') is None:
                tag_name = elem.tag.split('}')[-1]
                header_data[tag_name] = elem.text

        # --- 4. Extract Financial Data (has a unitRef) ---
        financial_data = []
        for elem in root.findall('in-capmkt:*', namespaces):
            if elem.get('contextRef') and elem.get('unitRef') is not None:
                tag_name = elem.tag.split('}')[-1]
                value_str = elem.text
                context_id = elem.get('contextRef')
                unit_id = elem.get('unitRef')
                decimals = elem.get('decimals')

                # Clean and convert value
                try:
                    value = float(value_str)

                    # Apply decimals. decimals="-6" means value is in millions.
                    # e.g. 5,062,000,000 with decimals="-6" is 5,062 (in millions)
                    # Let's calculate the "as reported" value if 'LevelOfRounding' is present
                    if header_data.get('LevelOfRounding') == 'Millions' and decimals == '-6':
                         value_reported = value / 1_000_000
                    elif header_data.get('LevelOfRounding') == 'Lakhs' and decimals == '-5':
                        value_reported = value / 100_000
                    else:
                        value_reported = value # Store as is if logic is unknown

                except (ValueError, TypeError):
                    value = value_str
                    value_reported = value_str

                financial_data.append({
                    'DataPoint': tag_name,
                    'Value': value,
                    'Value (Reported)': value_reported,
                    'Decimals': decimals,
                    'Unit': units.get(unit_id, unit_id),
                    'Period': contexts.get(context_id, context_id),
                    'ContextID': context_id
                })

        print(f"--- Successfully parsed {len(financial_data)} data points. ---")

        # Create DataFrame
        df = pd.DataFrame(financial_data)

        # Reorder columns for clarity
        df = df[['DataPoint', 'Value (Reported)', 'Unit', 'Period', 'Value', 'Decimals', 'ContextID']]

        return header_data, df

    except ET.ParseError as e:
        print(f"Error parsing XML: {e}")
        return None, None
    except FileNotFoundError:
        print(f"Error: File not found at '{xml_file}'")
        return None, None

def classify_statement(datapoint_name):
    """
    Classifies a financial DataPoint into a statement type.
    This is a simplified classification based on common XBRL tags.
    """
    datapoint_name_lower = datapoint_name.lower()
    if 'revenue' in datapoint_name_lower or \
       'income' in datapoint_name_lower or \
       'profit' in datapoint_name_lower or \
       'expense' in datapoint_name_lower or \
       'cost' in datapoint_name_lower or \
       'tax' in datapoint_name_lower:
        return 'Income Statement'
    elif 'asset' in datapoint_name_lower or \
         'liability' in datapoint_name_lower or \
         'equity' in datapoint_name_lower:
        return 'Balance Sheet'
    elif 'cashflow' in datapoint_name_lower or \
         'cash flow' in datapoint_name_lower:
        return 'Cash Flow Statement'
    else:
        return 'Other Financial Data'

def format_datapoint_name(name):
    """
    Formats a CamelCase data point name into a more readable string with spaces.
    e.g., 'AdjustmentsForDecreaseIncreaseInOtherCurrentAssets' -> 'Adjustments For Decrease Increase In Other Current Assets'
    """
    # Insert a space before any uppercase letter that is not at the beginning of the string,
    # or before an uppercase letter that is followed by a lowercase letter (to handle acronyms like 'INR')
    # and then remove leading/trailing spaces.
    formatted_name = re.sub(r'(?<!^)(?=[A-Z])', r' ', name).strip()
    # Handle cases like 'CashFlowsFromLosingControlOfSubsidiariesOrOtherBusinessesClassifiedAsInvestingActivities'
    # where some parts might still be clumped if they are all caps or specific patterns.
    # This simple regex handles most common CamelCase scenarios.
    return formatted_name

def main():
    # --- Configuration ---
    # Ask user for the file name
    FILE_NAME = input("Please enter the path to the XBRL XML file (e.g., INTEGRATED_FILING_INDAS_1570420_10112025081849_WEB.xml): ")
    # OUTPUT_FILE = "extracted_financial_data.xlsx" # Removed from config

    # 1. Run dependency check (removed from main as it's run once at top-level)

    # 2. Check if file exists
    if not os.path.exists(FILE_NAME):
        print(f"Error: The file '{FILE_NAME}' was not found in this directory.")
        print("Please make sure you have uploaded it to the Colab session or it is in the same folder as the script.")
        return

    # 3. Parse the data
    header_data, df = parse_xbrl_xml(FILE_NAME)

    if df is None:
        print("--- Data extraction failed. ---")
        return

    # 4. Present the extracted data
    print("\n--- ðŸ“Š Extracted Header Info ---")
    for key, value in header_data.items():
        print(f"  {key}: {value}")

    print("\n\n--- ðŸ“Š Extracted Financial Data (Vertical List, Sorted by Statement) ---")

    # Add StatementType column for sorting
    df['StatementType'] = df['DataPoint'].apply(classify_statement)

    # Sort the DataFrame by StatementType, then Period, then DataPoint for consistent order
    df_sorted = df.sort_values(by=['StatementType', 'Period', 'DataPoint'])

    current_statement_type = None
    # Get the global LevelOfRounding from header_data, default to empty string if not found
    level_of_rounding_suffix = header_data.get('LevelOfRounding', '')

    for index, row in df_sorted.iterrows():
        if row['StatementType'] != current_statement_type:
            current_statement_type = row['StatementType']
            print(f"\n----- {current_statement_type} -----")

        display_unit = row['Unit']

        # Special handling for units containing 'per shares' or 'pure'
        # to ensure magnitude suffix is not added or is removed if already present
        if "per shares" in str(display_unit).lower():
            # If 'per shares' unit already contains a magnitude, remove it
            display_unit = display_unit.replace(" Millions", "").replace(" Lakhs", "").replace(" Thousands", "").replace(" Billion Cr", "").strip()
            # Do NOT append the global level_of_rounding_suffix
        elif "pure" in str(display_unit).lower():
            # 'pure' units also typically don't have a magnitude suffix
            display_unit = display_unit.replace(" Millions", "").replace(" Lakhs", "").replace(" Thousands", "").replace(" Billion Cr", "").strip()
            # Do NOT append the global level_of_rounding_suffix
        elif level_of_rounding_suffix and level_of_rounding_suffix != 'None':
            # For other units (like 'INR'), append the global LevelOfRounding if available
            display_unit = f"{display_unit} {level_of_rounding_suffix}"

        # Format the DataPoint name for better readability
        formatted_datapoint_name = format_datapoint_name(row['DataPoint'])

        print(f"  {formatted_datapoint_name}")
        print(f"    Value (Reported): {row['Value (Reported)']:.2f} {display_unit}")
        print(f"    Period: {row['Period']}")
        print("-" * 30) # Separator for readability

    print(f"\nTotal data points extracted: {len(df)}")

    # 5. Removed saving to Excel as requested
    # try:
    #     df.to_excel(OUTPUT_FILE, index=False, sheet_name='ExtractedData')
    #     print(f"\n--- âœ… Success! All {len(df)} data points saved to '{OUTPUT_FILE}' ---")
    # except Exception as e:
    #     print(f"\n--- Error saving to Excel: {e} ---")

if __name__ == "__main__":
    main()